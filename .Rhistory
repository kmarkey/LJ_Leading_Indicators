group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID)) %>%
dplyr::filter(game_n >= 15 & `MIN` >= 15) %>%
dplyr::select(PLAYER_ID, all_of(cols))
View(before)
x <- before %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(across(all_of(cols), mean(.)))
x <- before %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(across(all_of(cols),~ mean(.)))
View(x)
x <- before %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(across(all_of(cols), ~ mean(.))) %>%
distinct()
before <- players %>%
dplyr::filter(game_date < as_start) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), mpg = `MIN` / game_n) %>%
dplyr::filter(game_n >= 15 & mpg >= 15) %>%
dplyr::select(PLAYER_ID, all_of(cols))
x <- before %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(across(all_of(cols), ~ mean(.))) %>%
distinct()
before <- players %>%
dplyr::filter(game_date < as_start) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), mpg = sum(`MIN`) / game_n) %>%
dplyr::filter(game_n >= 15 & mpg >= 15) %>%
dplyr::select(PLAYER_ID, all_of(cols))
x <- before %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(across(all_of(cols), ~ mean(.))) %>%
distinct()
after <- players %>%
dplyr::filter(game_date > as_end) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), total_points = sum(PTS)) %>%
dplyr::filter(game_n >= 15 & `MIN` >= 15) %>%
dplyr::mutate(y = ifelse(total_points / game_n > 15, 1, 0)) %>%
dplur::select(PLAYER_ID, y)
after <- players %>%
dplyr::filter(game_date > as_end) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), total_points = sum(PTS)) %>%
dplyr::filter(game_n >= 15 & `MIN` >= 15) %>%
dplyr::mutate(y = ifelse(total_points / game_n > 15, 1, 0)) %>%
dplyr::select(PLAYER_ID, y)
joined <- left_join(x, after)
View(joined)
after <- players %>%
dplyr::filter(game_date > as_end) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), total_points = sum(PTS)) %>%
dplyr::filter(game_n >= 15 & `MIN` >= 15) %>%
dplyr::mutate(y = ifelse(total_points / game_n > 15, 1, 0)) %>%
dplyr::select(PLAYER_ID, y) %>%
distinct()
joined <- left_join(x, after)
View(joined)
joined <- left_join(x, after) %>%
dplyr::filter(!is.na(y))
joined <- left_join(x, after, by = "PLAYER_ID") %>%
dplyr::filter(!is.na(y))
joined <- left_join(x, after, by = "PLAYER_ID") %>%
dplyr::filter(!is.na(y)) %>%
dplyr::select(PLAYER_ID)
mod <- glm(y ~., joined)
mod <- glm(y ~., data = joined, family = "binomial")
joined <- left_join(x, after, by = "PLAYER_ID") %>%
dplyr::filter(!is.na(y)) %>%
dplyr::select(-PLAYER_ID)
mod <- glm(y ~., data = joined, family = "binomial")
summary(mond)
summary(mod)
mod$R
mod$effects
mod$xlevels
summary(mod)
sign(mod)
coef(mod)
coef(mod)[2]
coef(summary(mod))[2]
coef(summary(mod))[,4]
t <- tibble(coef(summary(mod))[,4])
View(t)
coef(summary(mod))[,3]
coef(summary(mod))[,5]
names(summary(mod))[,2]
names(summary(mod))
coef(summary(mod))[,1]
names(coef(summary(mod))[,4])
t <- tibble(coef(summary(mod))[,4], names(coef(summary(mod))[,4]))
t <- tibble(PREDICTOR = names(coef(summary(mod))[,4]), P_VAL = coef(summary(mod))[,4])
write_csv(t, "LocalRStudio/assesssment/logistic_results.csv")
c <- matthew %>%
dplyr::filter(PERIOD == 2) %>%
dplyr::select(HOME_PLAYER_ID_1, HOME_PLAYER_ID_2, HOME_PLAYER_ID_3,
HOME_PLAYER_ID_4, HOME_PLAYER_ID_5,
AWAY_PLAYER_ID_1, AWAY_PLAYER_ID_2, AWAY_PLAYER_ID_3,
AWAY_PLAYER_ID_4, AWAY_PLAYER_ID_5)
C <- matthew %>%
dplyr::filter(PERIOD == 2) %>%
dplyr::select(HOME_PLAYER_ID_1, HOME_PLAYER_ID_2, HOME_PLAYER_ID_3,
HOME_PLAYER_ID_4, HOME_PLAYER_ID_5,
AWAY_PLAYER_ID_1, AWAY_PLAYER_ID_2, AWAY_PLAYER_ID_3,
AWAY_PLAYER_ID_4, AWAY_PLAYER_ID_5)
pairs <-
Map(function(x, y) apply(C[, x:y], 1, paste0, collapse="-"), 1:(ncol(C) - 1), 2:ncol(C))
as.data.frame(sort(table(unlist(pairs)), decreasing = T)[1:10])
as.data.frame(sort(table(unlist(pairs)), decreasing = T)[1:10])
pairs <-
Map(
function(x, y, z)
apply(C[, x:y:Z], 1, paste0, collapse = "-"), 1:(ncol(C) - 1), 2:ncol(C))
C2 <- matthew %>%
dplyr::filter(PERIOD == 2) %>% # 2nd quarter
dplyr::select(p1 = HOME_PLAYER_ID_1, p2 = HOME_PLAYER_ID_2, p3 = HOME_PLAYER_ID_3,
p4 = HOME_PLAYER_ID_4, p5 = HOME_PLAYER_ID_5)
p4 = AWAY_PLAYER_ID_4, p5 = AWAY_PLAYER_ID_5, `MIN`, GAME_ID)
C2 <-
bind_rows(matthew %>%
dplyr::filter(PERIOD == 2) %>% # 2nd quarter
dplyr::select(p1 = HOME_PLAYER_ID_1, p2 = HOME_PLAYER_ID_2, p3 = HOME_PLAYER_ID_3,
p4 = HOME_PLAYER_ID_4, p5 = HOME_PLAYER_ID_5, `MIN`, GAME_ID),
matthew %>%
dplyr::filter(PERIOD == 2) %>%
dplyr::select(p1 = AWAY_PLAYER_ID_1, p2 = AWAY_PLAYER_ID_2, p3 = AWAY_PLAYER_ID_3,
p4 = AWAY_PLAYER_ID_4, p5 = AWAY_PLAYER_ID_5, `MIN`, GAME_ID))
C2 <-
bind_rows(matthew %>%
dplyr::filter(PERIOD == 2) %>% # 2nd quarter
dplyr::select(p1 = HOME_PLAYER_ID_1, p2 = HOME_PLAYER_ID_2, p3 = HOME_PLAYER_ID_3,
p4 = HOME_PLAYER_ID_4, p5 = HOME_PLAYER_ID_5, `MIN`, GAME_ID),
matthew %>%
dplyr::filter(PERIOD == 2) %>%
dplyr::select(p1 = AWAY_PLAYER_ID_1, p2 = AWAY_PLAYER_ID_2, p3 = AWAY_PLAYER_ID_3,
p4 = AWAY_PLAYER_ID_4, p5 = AWAY_PLAYER_ID_5, `MIN`, GAME_ID))
C2 <-
bind_rows(matthew %>%
dplyr::filter(PERIOD == 2) %>% # 2nd quarter
dplyr::select(p1 = HOME_PLAYER_ID_1, p2 = HOME_PLAYER_ID_2, p3 = HOME_PLAYER_ID_3,
p4 = HOME_PLAYER_ID_4, p5 = HOME_PLAYER_ID_5, TIME, GAME_ID),
matthew %>%
dplyr::filter(PERIOD == 2) %>%
dplyr::select(p1 = AWAY_PLAYER_ID_1, p2 = AWAY_PLAYER_ID_2, p3 = AWAY_PLAYER_ID_3,
p4 = AWAY_PLAYER_ID_4, p5 = AWAY_PLAYER_ID_5, TIME, GAME_ID))
q <- C2 %>%
group_by(across(GAME_ID, p1, p2, p3, p4, p5), ~sum(TIME))
q <- C2 %>%
group_by(across(GAME_ID, p1, p2, p3, p4, p5, ~sum(TIME)))
group_by(across(GAME_ID, p1, p2, p3, p4, p5, .fns = list(group_time = ~sum(TIME)))
q <- C2 %>%
group_by(across(GAME_ID, p1, p2, p3, p4, p5, .fns = list(group_time = ~sum(TIME))))
q <- C2 %>%
group_by(across(GAME_ID, p1, p2, p3, p4, p5, .fns = list(group_time = ~sum(TIME))))
View(q)
q <- C2 %>%
group_by(across(GAME_ID, p1, p2, p3, p4, p5, .fns = list(group_time = ~range(TIME))))
q <- C2 %>%
group_by(across(GAME_ID, p1, p2, p3, p4, p5, .fns = list(group_time = ~max(TIME)-min(TIME))))
Canswer <- as.data.frame(sort(table(unlist(pairs)), decreasing = T)[1:10])
C %>%
dplyr::count(p1, p2, p3, p4, p5)
C2 %>%
dplyr::count(p1, p2, p3, p4, p5)
C2 %>%
dplyr::count(p1, p2, p3, p4, p5, sort = TRUE)
C2[203110]
C2[,203110]
C2["203110"]
C2[, 1]
sum(C2[, 1] == 203110)
sum(C2[, 2] == 203110)
sum(C2[, 3] == 203110)
sum(C2[, 4] == 203110)
sum(C2[, 5] == 203110)
C2 %>%
dplyr::count(p1, p2, p3, p4, p5, sort = TRUE)
# 2-player more algorithmic solution from
# https://stackoverflow.com/questions/62373173/r-how-to-find-the-10-most-common-pairs-by-row-across-5-variables-in-a-df?answertab=trending#tab-top
# but not based on minutes
pairs <-
Map(
function(x, y)
apply(C[, x:y], 1, paste0), 1:(ncol(C) - 1), 2:ncol(C))
Canswer <- as.data.frame(sort(table(unlist(pairs)), decreasing = T)[1:10])
Canswer
Canswer stack %>%
separate(Var1, into = c("PLAYER_1", "PLAYER_2"), sep = "-")
stack <- as.data.frame(sort(table(unlist(pairs)), decreasing = T)[1:10])
View(stack)
Canswer stack %>%
separate(Var1, into = c("PLAYER_1", "PLAYER_2"), sep = "-")
Canswer <- stack %>%
separate(Var1, into = c("PLAYER_1", "PLAYER_2"), sep = "-")
View(Canswer)
View(stack)
# 2-player more algorithmic solution from
# https://stackoverflow.com/questions/62373173/r-how-to-find-the-10-most-common-pairs-by-row-across-5-variables-in-a-df?answertab=trending#tab-top
# but not based on minutes
pairs <-
Map(
function(x, y)
apply(C[, x:y], 1, paste0, collapse = "-"), 1:(ncol(C) - 1), 2:ncol(C))
stack <- as.data.frame(sort(table(unlist(pairs)), decreasing = T)[1:10])
Canswer <- stack %>%
separate(Var1, into = c("PLAYER_1", "PLAYER_2"), sep = "-")
write_csv(Canswer, "LocalRStudio/assesssment/top_trios.csv)
## D
as_start <- "2022-02-18"
as_end <- "2022-02-20"
cols <- c("FG_PCT", "FG3A", "FTA", "AST", "TOV", "OREB")
# separate into before and after, then join
before <- players %>%
dplyr::filter(game_date < as_start) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), mpg = sum(`MIN`) / game_n) %>%
dplyr::filter(game_n >= 15 & mpg >= 15) %>%
dplyr::select(PLAYER_ID, all_of(cols))
x <- before %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(across(all_of(cols), ~ mean(.))) %>%
distinct()
after <- players %>%
dplyr::filter(game_date > as_end) %>%
group_by(PLAYER_ID) %>%
dplyr::mutate(game_n = length(PLAYER_ID), total_points = sum(PTS)) %>%
dplyr::filter(game_n >= 15 & `MIN` >= 15) %>%
dplyr::mutate(y = ifelse(total_points / game_n > 15, 1, 0)) %>%
dplyr::select(PLAYER_ID, y) %>%
distinct()
joined <- left_join(x, after, by = "PLAYER_ID") %>%
dplyr::filter(!is.na(y)) %>% # trim up before/after players
dplyr::select(-PLAYER_ID)
# logreg
mod <- glm(y ~., data = joined, family = "binomial")
summary(mod)
t <- tibble(PREDICTOR = names(coef(summary(mod))[,4]), P_VAL = coef(summary(mod))[,4])
write_csv(t, "LocalRStudio/assesssment/logistic_results.csv")
write_csv(t, "LocalRStudio/assesssment/logistic_results.csv")
write_csv(Canswer, "LocalRStudio/assesssment/top_trios.csv")
pop <- read_csv("data/census2020pop.csv") %>%
dplyr::mutate(name = tolower(NAME)) %>%
right_join(statekey, by = "name") %>%
summarise(name, abb, num, pop = ESTIMATESBASE2020, per = pop / sum(ESTIMATESBASE2020))
source("~/LocalRStudio/mhealth/figgen.R", echo=TRUE)
source("~/LocalRStudio/mhealth/figgen.R", echo=TRUE)
getwd()
library(here)
setwd("LocalRStudio/mhealth352")
setwd("LocalRStudio/mhealth352")
setwd("LocalRStudio/mhealth352")
getwd()
source("digest.R")
setwd("~/LocalRStudio/mhealth352")
setwd("LocalRStudio/mhealth352")
source("~/LocalRStudio/LJ_Leading_Indicators/Digest.R", echo=TRUE)
source("~/LocalRStudio/LJ_Leading_Indicators/Digest.R")
keys <- read_delim("keys/kets.txt")
keys <- read_delim("/keys/kets.txt")
keys <- read_delim("keys/keys.txt")
View(keys)
keys <- read_delim("keys/keys.txt")
View(keys)
keys <- read_delim("keys/keys.txt", header = FALSE)
keys <- read_delim("keys/keys.txt")
keys <- read_delim("keys/keys.txt")
keys["Domain",]
keys["Quandl", 2]
keys["Quandl", 1]
keys[1, "Quandl"]
keys["Quandl"]
keys["Quandl", ]
keys["Quandl", 2]
keys["Quandl", 3]
View(keys)
keys["quandl_key",]
keys["quandl_key", ]
keys <- read_delim("keys/keys.txt")
keys["quandl_key", ]
keys[1, 2]
keys[1, 1]
keys[2, 2]
keys["quandl_key"]
keys[,"quandl_key"]
keys["quandl_key",]
keys["quandl_key",,]
keys["quandl_key",,]
keys["quandl_key",,,]
keys[1, "quandl_key",,,]
keys[1, "quandl_key"]
list(keys)
keys <- list(read_delim("keys/keys.txt"))
keys["quandl_key"]
list(keys)
keys
keys <- list(read_delim("keys/keys.txt", trim_ws = TRUE))
keys[]
names(keys)
values(keys)
keys[1]
keys[2]
keys <- as.list(read_delim("keys/keys.txt", trim_ws = TRUE))
keys[]
keys["quandl_key"]
keys[]
keys$key[keys$domain["quandl_key"]]
keys$domain["quandl_key"]
keys$domain
keys$domain["mysqlroot"]
keys$domain[1]
keys <- read_delim("keys/keys.txt", trim_ws = TRUE)
keys
keys[4,2]
Quandl.api_key(keys[4,2])
keys <- read_delim("keys/keys.txt", trim_ws = TRUE)
keys[4,2]
Quandl.api_key(keys[4,2])
Mazda <- read_csv("data/in/stocks/MZDAY.csv")
Hyundai <- read_csv("data/in/stocks/HYMTF.csv")
stocks <- blank_m %>%
left_join(GM, by = "date") %>%
left_join(FB, by = "date") %>%
left_join(AN, by = "date") %>%
left_join(TSLA, by = "date") %>%# arranges high to low
left_join(Hyundai, by = "date") %>%
left_join(Mazda, by = "date") %>%
dplyr::mutate(across(is.numeric, .fns = list(raw = ~.,
lag1 = ~ lag(., 1),
lag2 = ~ lag(., 2),
lag3 = ~ lag(., 3),
lag6 = ~ lag(., 6),
lag12 = ~ lag(., 12)),
.names = "{.col}_{.fn}"),
.keep = "unused")
exam(stocks, cor_max)
source("~/LocalRStudio/LJ_Leading_Indicators/Digest.R")
source("~/LocalRStudio/LJ_Leading_Indicators/Digest.R")
spec(month)
# read in month
month <- read_csv("data/out/month.csv")
# read in keys
keys <- read_delim("keys/keys.txt", trim_ws = TRUE)
Quandl.api_key(keys[4,2])
# create date bounaries
search_bottom <- min(month$date) - years(1) # from month
search_bottom
search_top <- ceiling_date(max(month$date), unit = "month") - 1
search_top
# set correlation threshold
cor_max <- 0.20
# blank df for join
blank_m <- tibble(date = seq.Date(from = search_bottom, to = search_top, by = "month"))
#=============================select quandl series==============================
# OPEC crude oil
oil <- quandl_lag("OPEC/ORB", x = "Value", prefix = "oil", search_bottom, search_top, blank_m)
exam(oil, cor_max)
#=============================select quandl series==============================
# OPEC crude oil
oil <- quandl_lag("OPEC/ORB", x = "Value", prefix = "oil", search_bottom, search_top, blank_m)
# E-mini Natural Gas Futures, Continuous Contract #1 (QG1) (Front Month)
NGF1 <- quandl_lag("CHRIS/CME_QG1", x = "Settle", prefix = "ngf1", search_bottom, search_top, blank_m)
View(oil)
Quandl.api_key('DLPMVwPNyH57sF6Z1iM4')
#=============================select quandl series==============================
# OPEC crude oil
oil <- quandl_lag("OPEC/ORB", x = "Value", prefix = "oil", search_bottom, search_top, blank_m)
exam(oil, cor_max)
keys[4,]
# read in keys
keys <- read_delim("keys/keys.txt", trim_ws = TRUE)
keys$key
keys$key[keys$domain["waudnl_key"]]
keys$key[keys$domain["qaudnl_key"]]
keys$key[keys$domain["quandl_key"]]
keys$domain[1]
keys$key[4]
as.character(keys$key[4])
Quandl.api_key(as.character(keys$key[4]))
#=============================select quandl series==============================
# OPEC crude oil
oil <- quandl_lag("OPEC/ORB", x = "Value", prefix = "oil", search_bottom, search_top, blank_m)
exam(oil, cor_max)
source("~/LocalRStudio/LJ_Leading_Indicators/Digest.R")
#=============================== google trends =================================
trends <- read_csv("data/in/trends.csv")
trends <- blank_m %>%
left_join(trends, by = "date") %>% # arranges high to low
dplyr::mutate(across(is.numeric, .fns = list(raw = ~.,
lag1 = ~ lag(., 1),
lag2 = ~ lag(., 2),
lag3 = ~ lag(., 3),
lag6 = ~ lag(., 6),
lag12 = ~ lag(., 12)),
.names = "{.col}_{.fn}"),
.keep = "unused")
scaling <- function(x) { # normalization function
return((x - min(x))/(max(x) - min(x)))
}
complete_dirty <- left_join(dplyr::select(month, date, n),  # combine all to 1 df
oil, by = "date") %>%
left_join(NGF1, by = "date") %>%
left_join(NGF2, by = "date") %>%
left_join(IR1, by = "date") %>%
left_join(HPISTB, by = "date") %>%
left_join(HPIWA, by = "date") %>%
left_join(FRM15, by = "date") %>%
left_join(FRM30, by = "date") %>%
left_join(ARM5, by = "date") %>%
# econ
left_join(fred, by = "date") %>%
left_join(stocks, by = "date") %>%
left_join(trends, by = "date") %>%
# google results
# add more later
#######################################
tibble::rowid_to_column("month") %>%
dplyr::select(-date)
#============================ wide filter to cor ===============================
write_csv(complete_dirty, "data/out/complete.csv")
# change date to month key col
complete_cor <- complete_dirty %>%
cor()
# select for co  >= 0.25
feature_dict <- complete_cor[complete_cor['n',] >= cor_max | complete_cor['n',] <= -cor_max, 'n']
# select features in features dict
features <- dplyr::select(complete_dirty, all_of(names(feature_dict))) %>%
dplyr::select(-ends_with(c("_raw", "_lag1", "_lag2")))
View(complete_dirty)
View(features)
# select features in features dict
features <- dplyr::select(complete_dirty, all_of(names(feature_dict))) %>%
dplyr::select(-ends_with(c("_raw", "_lag1", "_lag2")))
# select for co  >= 0.25
feature_dict <- complete_cor[complete_cor['n',] >= cor_max | complete_cor['n',] <= -cor_max, 'n']
feature_dict
# change date to month key col
complete_cor <- complete_dirty %>%
cor()
View(complete_cor)
is.na(feature_dict)
is.na(feature_dict) ==TRUE
View(Hyundai)
View(Hyundai)
Hyundai <- read_csv("data/in/stocks/HYMTF.csv")
View(Hyundai)
stocks <- blank_m %>%
left_join(GM, by = "date") %>%
left_join(FB, by = "date") %>%
left_join(AN, by = "date") %>%
left_join(TSLA, by = "date") %>%# arranges high to low
# left_join(Hyundai, by = "date") %>%
left_join(Mazda, by = "date") %>%
dplyr::mutate(across(is.numeric, .fns = list(raw = ~.,
lag1 = ~ lag(., 1),
lag2 = ~ lag(., 2),
lag3 = ~ lag(., 3),
lag6 = ~ lag(., 6),
lag12 = ~ lag(., 12)),
.names = "{.col}_{.fn}"),
.keep = "unused")
exam(stocks, cor_max)
#=============================== google trends =================================
trends <- read_csv("data/in/trends.csv")
trends <- blank_m %>%
left_join(trends, by = "date") %>% # arranges high to low
dplyr::mutate(across(is.numeric, .fns = list(raw = ~.,
lag1 = ~ lag(., 1),
lag2 = ~ lag(., 2),
lag3 = ~ lag(., 3),
lag6 = ~ lag(., 6),
lag12 = ~ lag(., 12)),
.names = "{.col}_{.fn}"),
.keep = "unused")
scaling <- function(x) { # normalization function
return((x - min(x))/(max(x) - min(x)))
}
complete_dirty <- left_join(dplyr::select(month, date, n),  # combine all to 1 df
oil, by = "date") %>%
left_join(NGF1, by = "date") %>%
left_join(NGF2, by = "date") %>%
left_join(IR1, by = "date") %>%
left_join(HPISTB, by = "date") %>%
left_join(HPIWA, by = "date") %>%
left_join(FRM15, by = "date") %>%
left_join(FRM30, by = "date") %>%
left_join(ARM5, by = "date") %>%
# econ
left_join(fred, by = "date") %>%
left_join(stocks, by = "date") %>%
left_join(trends, by = "date") %>%
# google results
# add more later
#######################################
tibble::rowid_to_column("month") %>%
dplyr::select(-date)
#============================ wide filter to cor ===============================
write_csv(complete_dirty, "data/out/complete.csv")
# change date to month key col
complete_cor <- complete_dirty %>%
cor()
# select for co  >= 0.25
feature_dict <- complete_cor[complete_cor['n',] >= cor_max | complete_cor['n',] <= -cor_max, 'n']
# select features in features dict
features <- dplyr::select(complete_dirty, all_of(names(feature_dict))) %>%
dplyr::select(-ends_with(c("_raw", "_lag1", "_lag2")))
#==================================== write out ================================
write_csv(features, "data/out/features.csv")
source("~/LocalRStudio/LJ_Leading_Indicators/Digest.R")
