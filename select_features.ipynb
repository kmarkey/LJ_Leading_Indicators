{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a999f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15432b78",
   "metadata": {},
   "source": [
    "Add appts, [last month/year?], home sales[can't find current], and more stocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cf813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 89)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/out/features.csv\")\n",
    "len(data), len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f601c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop(columns = ['n']), data['n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55299d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb94fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d297fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Lasso())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6c815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline,\n",
    "                      {'model__alpha':np.arange(0.0, 30, 0.5)},\n",
    "                      cv = 5,\n",
    "                      scoring = 'neg_mean_squared_error',\n",
    "                      verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1631a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV 1/5] END ............model__alpha=0.0;, score=-275582.484 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=0.0;, score=-36346.825 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=0.0;, score=-13052.674 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=0.0;, score=-19437.358 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=0.0;, score=-123954.609 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=0.5;, score=-33956.968 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=0.5;, score=-13366.182 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=0.5;, score=-5951.394 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=0.5;, score=-6607.073 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=0.5;, score=-69995.102 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=1.0;, score=-41903.119 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=1.0;, score=-9268.968 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=1.0;, score=-4985.616 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=1.0;, score=-7672.847 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=1.0;, score=-61132.673 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=1.5;, score=-42349.756 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.390e+02, tolerance: 2.769e+01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.497e+01, tolerance: 2.867e+01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+01, tolerance: 2.832e+01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "C:\\Users\\keato\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.125e+01, tolerance: 2.769e+01\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..............model__alpha=1.5;, score=-8807.140 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=1.5;, score=-3785.261 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=1.5;, score=-7905.334 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=1.5;, score=-54170.387 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=2.0;, score=-43922.523 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=2.0;, score=-7190.306 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=2.0;, score=-2707.275 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=2.0;, score=-6587.147 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=2.0;, score=-43706.230 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=2.5;, score=-35594.594 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=2.5;, score=-6218.788 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=2.5;, score=-2121.396 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=2.5;, score=-4828.889 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=2.5;, score=-35633.517 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=3.0;, score=-26999.708 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=3.0;, score=-5419.551 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=3.0;, score=-2024.662 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=3.0;, score=-3553.576 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=3.0;, score=-28706.607 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=3.5;, score=-20040.363 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=3.5;, score=-4632.871 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=3.5;, score=-1996.181 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=3.5;, score=-3090.754 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=3.5;, score=-24244.225 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=4.0;, score=-14715.434 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=4.0;, score=-4071.750 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=4.0;, score=-1753.329 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=4.0;, score=-3010.300 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=4.0;, score=-20990.202 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=4.5;, score=-10557.017 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=4.5;, score=-3628.515 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=4.5;, score=-1552.596 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=4.5;, score=-2938.063 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=4.5;, score=-18578.651 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=5.0;, score=-8159.561 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=5.0;, score=-3337.017 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=5.0;, score=-1489.956 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=5.0;, score=-2880.307 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=5.0;, score=-16475.019 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=5.5;, score=-7355.196 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=5.5;, score=-3251.853 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=5.5;, score=-1456.182 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=5.5;, score=-2835.639 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=5.5;, score=-15718.518 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=6.0;, score=-6483.265 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=6.0;, score=-3278.022 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=6.0;, score=-1456.921 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=6.0;, score=-2746.969 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=6.0;, score=-15211.055 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=6.5;, score=-5649.855 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=6.5;, score=-3377.120 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=6.5;, score=-1459.567 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=6.5;, score=-2627.942 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=6.5;, score=-15207.977 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=7.0;, score=-4839.164 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=7.0;, score=-3465.507 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=7.0;, score=-1489.595 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=7.0;, score=-2509.645 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=7.0;, score=-15868.230 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=7.5;, score=-4269.841 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=7.5;, score=-3478.842 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=7.5;, score=-1530.765 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=7.5;, score=-2456.632 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=7.5;, score=-17141.709 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=8.0;, score=-3752.312 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=8.0;, score=-3507.236 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=8.0;, score=-1583.110 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=8.0;, score=-2442.211 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=8.0;, score=-18157.901 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=8.5;, score=-3294.228 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=8.5;, score=-3537.323 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=8.5;, score=-1630.102 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=8.5;, score=-2432.580 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=8.5;, score=-19125.938 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=9.0;, score=-2865.547 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=9.0;, score=-3562.320 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=9.0;, score=-1655.896 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=9.0;, score=-2416.284 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=9.0;, score=-19520.620 total time=   0.0s\n",
      "[CV 1/5] END ..............model__alpha=9.5;, score=-2465.384 total time=   0.0s\n",
      "[CV 2/5] END ..............model__alpha=9.5;, score=-3591.872 total time=   0.0s\n",
      "[CV 3/5] END ..............model__alpha=9.5;, score=-1667.468 total time=   0.0s\n",
      "[CV 4/5] END ..............model__alpha=9.5;, score=-2351.751 total time=   0.0s\n",
      "[CV 5/5] END .............model__alpha=9.5;, score=-19778.105 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=10.0;, score=-2236.886 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=10.0;, score=-3640.321 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=10.0;, score=-1656.563 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=10.0;, score=-2249.021 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=10.0;, score=-20029.737 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=10.5;, score=-2087.044 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=10.5;, score=-3701.380 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=10.5;, score=-1645.951 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=10.5;, score=-2164.328 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=10.5;, score=-20270.477 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=11.0;, score=-1947.217 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=11.0;, score=-3764.179 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=11.0;, score=-1639.702 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=11.0;, score=-2093.178 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=11.0;, score=-20504.798 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=11.5;, score=-1836.775 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=11.5;, score=-3830.698 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=11.5;, score=-1630.678 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=11.5;, score=-2048.999 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=11.5;, score=-20714.819 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=12.0;, score=-1748.530 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=12.0;, score=-3873.806 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=12.0;, score=-1622.369 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=12.0;, score=-2016.960 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=12.0;, score=-20927.044 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=12.5;, score=-1677.191 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=12.5;, score=-3883.542 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=12.5;, score=-1616.274 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .............model__alpha=12.5;, score=-1986.153 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=12.5;, score=-21142.350 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=13.0;, score=-1562.385 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=13.0;, score=-3892.498 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=13.0;, score=-1623.355 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=13.0;, score=-1956.567 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=13.0;, score=-21277.187 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=13.5;, score=-1470.543 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=13.5;, score=-3902.447 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=13.5;, score=-1631.025 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=13.5;, score=-1928.201 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=13.5;, score=-21394.293 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=14.0;, score=-1390.421 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=14.0;, score=-3913.408 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=14.0;, score=-1639.188 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=14.0;, score=-1906.135 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=14.0;, score=-21511.906 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=14.5;, score=-1320.422 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=14.5;, score=-3925.377 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=14.5;, score=-1647.383 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=14.5;, score=-1887.565 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=14.5;, score=-21596.752 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=15.0;, score=-1260.544 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=15.0;, score=-3938.354 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=15.0;, score=-1641.614 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=15.0;, score=-1871.185 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=15.0;, score=-21618.275 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=15.5;, score=-1210.676 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=15.5;, score=-3952.339 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=15.5;, score=-1636.266 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=15.5;, score=-1855.652 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=15.5;, score=-21617.040 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=16.0;, score=-1171.067 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=16.0;, score=-3967.332 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=16.0;, score=-1631.335 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=16.0;, score=-1841.006 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=16.0;, score=-21615.845 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=16.5;, score=-1141.589 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=16.5;, score=-3983.332 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=16.5;, score=-1626.813 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=16.5;, score=-1827.221 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=16.5;, score=-21614.690 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=17.0;, score=-1121.600 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=17.0;, score=-4000.343 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=17.0;, score=-1621.840 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=17.0;, score=-1814.292 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=17.0;, score=-21613.575 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=17.5;, score=-1103.984 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=17.5;, score=-4016.559 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=17.5;, score=-1615.560 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=17.5;, score=-1802.235 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=17.5;, score=-21612.500 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=18.0;, score=-1095.687 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=18.0;, score=-4033.037 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=18.0;, score=-1609.372 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=18.0;, score=-1791.046 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=18.0;, score=-21611.465 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=18.5;, score=-1090.461 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=18.5;, score=-4050.617 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=18.5;, score=-1603.274 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=18.5;, score=-1780.672 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=18.5;, score=-21610.469 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=19.0;, score=-1091.710 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=19.0;, score=-4069.222 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=19.0;, score=-1597.265 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=19.0;, score=-1771.172 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=19.0;, score=-21609.514 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=19.5;, score=-1117.308 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=19.5;, score=-4099.896 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=19.5;, score=-1591.346 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=19.5;, score=-1761.960 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=19.5;, score=-21608.598 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=20.0;, score=-1141.838 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=20.0;, score=-4134.523 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=20.0;, score=-1585.514 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=20.0;, score=-1753.033 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=20.0;, score=-21607.722 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=20.5;, score=-1145.305 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=20.5;, score=-4170.612 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=20.5;, score=-1576.612 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=20.5;, score=-1744.393 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=20.5;, score=-21606.886 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=21.0;, score=-1132.640 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=21.0;, score=-4208.119 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=21.0;, score=-1566.327 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=21.0;, score=-1736.040 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=21.0;, score=-21606.090 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=21.5;, score=-1120.932 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=21.5;, score=-4247.068 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=21.5;, score=-1556.155 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=21.5;, score=-1727.973 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=21.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=22.0;, score=-1111.077 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=22.0;, score=-4287.459 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=22.0;, score=-1546.094 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=22.0;, score=-1720.194 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=22.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=22.5;, score=-1103.104 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=22.5;, score=-4329.289 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=22.5;, score=-1536.128 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=22.5;, score=-1712.701 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=22.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=23.0;, score=-1094.305 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=23.0;, score=-4372.559 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=23.0;, score=-1526.293 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .............model__alpha=23.0;, score=-1705.494 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=23.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=23.5;, score=-1086.991 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=23.5;, score=-4417.261 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=23.5;, score=-1516.569 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=23.5;, score=-1698.573 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=23.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=24.0;, score=-1081.426 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=24.0;, score=-4473.778 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=24.0;, score=-1506.958 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=24.0;, score=-1691.950 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=24.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=24.5;, score=-1077.609 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=24.5;, score=-4527.504 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=24.5;, score=-1497.443 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=24.5;, score=-1682.840 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=24.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=25.0;, score=-1075.539 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=25.0;, score=-4546.572 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=25.0;, score=-1488.057 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=25.0;, score=-1674.202 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=25.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=25.5;, score=-1075.217 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=25.5;, score=-4566.021 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=25.5;, score=-1478.782 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=25.5;, score=-1666.521 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=25.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=26.0;, score=-1076.644 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=26.0;, score=-4585.848 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=26.0;, score=-1469.620 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=26.0;, score=-1659.812 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=26.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=26.5;, score=-1079.820 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=26.5;, score=-4606.064 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=26.5;, score=-1460.557 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=26.5;, score=-1654.073 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=26.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=27.0;, score=-1084.744 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=27.0;, score=-4626.649 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=27.0;, score=-1451.618 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=27.0;, score=-1649.324 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=27.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=27.5;, score=-1091.417 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=27.5;, score=-4647.616 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=27.5;, score=-1442.777 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=27.5;, score=-1645.529 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=27.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=28.0;, score=-1099.839 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=28.0;, score=-4668.957 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=28.0;, score=-1441.281 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=28.0;, score=-1642.707 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=28.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=28.5;, score=-1110.009 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=28.5;, score=-4691.340 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=28.5;, score=-1443.316 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=28.5;, score=-1640.857 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=28.5;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=29.0;, score=-1121.928 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=29.0;, score=-4714.618 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=29.0;, score=-1447.126 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=29.0;, score=-1639.969 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=29.0;, score=-21605.664 total time=   0.0s\n",
      "[CV 1/5] END .............model__alpha=29.5;, score=-1135.596 total time=   0.0s\n",
      "[CV 2/5] END .............model__alpha=29.5;, score=-4737.272 total time=   0.0s\n",
      "[CV 3/5] END .............model__alpha=29.5;, score=-1451.044 total time=   0.0s\n",
      "[CV 4/5] END .............model__alpha=29.5;, score=-1640.055 total time=   0.0s\n",
      "[CV 5/5] END ............model__alpha=29.5;, score=-21605.664 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('model', Lasso())]),\n",
       "             param_grid={'model__alpha': array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "        5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5,\n",
       "       11. , 11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5, 15. , 15.5, 16. ,\n",
       "       16.5, 17. , 17.5, 18. , 18.5, 19. , 19.5, 20. , 20.5, 21. , 21.5,\n",
       "       22. , 22.5, 23. , 23.5, 24. , 24.5, 25. , 25.5, 26. , 26.5, 27. ,\n",
       "       27.5, 28. , 28.5, 29. , 29.5])},\n",
       "             scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6468872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 7.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2666d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = search.best_estimator_[1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c242e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment_lag6', 'new_units_lag12', 'GM_lag12', 'GM_v_lag12',\n",
       "       'F_v_lag12', 'TSLA_v_lag3', 'AN_v_lag3', 'XOM_lag6',\n",
       "       'g_best_new_cars_lag3', 'g_best_new_cars_lag12', 'oil_lag12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = X.iloc[:, coef != 0]\n",
    "out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a7ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.insert(0, 'n', y, True)\n",
    "out.insert(0, 'month', X['month'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50757784",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"data/out/lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b3ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>n</th>\n",
       "      <th>sentiment_lag6</th>\n",
       "      <th>new_units_lag12</th>\n",
       "      <th>GM_lag12</th>\n",
       "      <th>GM_v_lag12</th>\n",
       "      <th>F_v_lag12</th>\n",
       "      <th>TSLA_v_lag3</th>\n",
       "      <th>AN_v_lag3</th>\n",
       "      <th>XOM_lag6</th>\n",
       "      <th>g_best_new_cars_lag3</th>\n",
       "      <th>g_best_new_cars_lag12</th>\n",
       "      <th>oil_lag12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>93.1</td>\n",
       "      <td>3967.330793</td>\n",
       "      <td>32.62</td>\n",
       "      <td>322791897</td>\n",
       "      <td>596534720</td>\n",
       "      <td>100854710</td>\n",
       "      <td>19192133</td>\n",
       "      <td>79.21</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "      <td>44.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>330</td>\n",
       "      <td>91.9</td>\n",
       "      <td>4624.848400</td>\n",
       "      <td>37.31</td>\n",
       "      <td>325763066</td>\n",
       "      <td>524657536</td>\n",
       "      <td>78487987</td>\n",
       "      <td>15208883</td>\n",
       "      <td>75.24</td>\n",
       "      <td>71</td>\n",
       "      <td>76</td>\n",
       "      <td>56.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>323</td>\n",
       "      <td>87.2</td>\n",
       "      <td>3249.005847</td>\n",
       "      <td>37.50</td>\n",
       "      <td>290497517</td>\n",
       "      <td>609892208</td>\n",
       "      <td>59852189</td>\n",
       "      <td>17266632</td>\n",
       "      <td>74.35</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>51.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>369</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2951.720587</td>\n",
       "      <td>35.06</td>\n",
       "      <td>397017858</td>\n",
       "      <td>539661690</td>\n",
       "      <td>79247152</td>\n",
       "      <td>39619066</td>\n",
       "      <td>82.74</td>\n",
       "      <td>77</td>\n",
       "      <td>87</td>\n",
       "      <td>62.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>392</td>\n",
       "      <td>91.3</td>\n",
       "      <td>3100.106707</td>\n",
       "      <td>35.97</td>\n",
       "      <td>247974427</td>\n",
       "      <td>428638676</td>\n",
       "      <td>133705697</td>\n",
       "      <td>45371013</td>\n",
       "      <td>81.66</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>60.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>329</td>\n",
       "      <td>92.6</td>\n",
       "      <td>3336.716121</td>\n",
       "      <td>33.33</td>\n",
       "      <td>301968673</td>\n",
       "      <td>577413238</td>\n",
       "      <td>102729544</td>\n",
       "      <td>33490119</td>\n",
       "      <td>77.95</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>58.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>420</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3023.300368</td>\n",
       "      <td>31.51</td>\n",
       "      <td>421897537</td>\n",
       "      <td>672367234</td>\n",
       "      <td>135507264</td>\n",
       "      <td>40381923</td>\n",
       "      <td>77.85</td>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>50.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>359</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3604.501487</td>\n",
       "      <td>29.44</td>\n",
       "      <td>388156191</td>\n",
       "      <td>596411983</td>\n",
       "      <td>103313344</td>\n",
       "      <td>23858141</td>\n",
       "      <td>80.15</td>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>47.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>368</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3352.754923</td>\n",
       "      <td>30.02</td>\n",
       "      <td>356102158</td>\n",
       "      <td>743132834</td>\n",
       "      <td>121687759</td>\n",
       "      <td>26540639</td>\n",
       "      <td>83.59</td>\n",
       "      <td>71</td>\n",
       "      <td>76</td>\n",
       "      <td>43.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>367</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2896.245248</td>\n",
       "      <td>34.91</td>\n",
       "      <td>324318496</td>\n",
       "      <td>669014321</td>\n",
       "      <td>74068654</td>\n",
       "      <td>25137021</td>\n",
       "      <td>88.40</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>43.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>350</td>\n",
       "      <td>94.7</td>\n",
       "      <td>3095.192580</td>\n",
       "      <td>36.20</td>\n",
       "      <td>211953154</td>\n",
       "      <td>443652862</td>\n",
       "      <td>62291339</td>\n",
       "      <td>23977786</td>\n",
       "      <td>89.02</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>38.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>414</td>\n",
       "      <td>93.5</td>\n",
       "      <td>2976.283249</td>\n",
       "      <td>34.01</td>\n",
       "      <td>228926730</td>\n",
       "      <td>587839387</td>\n",
       "      <td>70644512</td>\n",
       "      <td>17778089</td>\n",
       "      <td>93.74</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>31.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>339</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3248.984736</td>\n",
       "      <td>29.64</td>\n",
       "      <td>376807104</td>\n",
       "      <td>1087248662</td>\n",
       "      <td>92133590</td>\n",
       "      <td>18464132</td>\n",
       "      <td>88.95</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>29.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>347</td>\n",
       "      <td>89.8</td>\n",
       "      <td>2923.248633</td>\n",
       "      <td>29.44</td>\n",
       "      <td>327501916</td>\n",
       "      <td>795712499</td>\n",
       "      <td>98886097</td>\n",
       "      <td>23079426</td>\n",
       "      <td>87.14</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>30.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>403</td>\n",
       "      <td>91.2</td>\n",
       "      <td>3511.378415</td>\n",
       "      <td>31.43</td>\n",
       "      <td>269313331</td>\n",
       "      <td>722921118</td>\n",
       "      <td>87993345</td>\n",
       "      <td>18497339</td>\n",
       "      <td>87.28</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>34.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>363</td>\n",
       "      <td>87.2</td>\n",
       "      <td>3490.467044</td>\n",
       "      <td>31.80</td>\n",
       "      <td>249296092</td>\n",
       "      <td>736025667</td>\n",
       "      <td>100683220</td>\n",
       "      <td>18467582</td>\n",
       "      <td>83.32</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>42.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>416</td>\n",
       "      <td>93.8</td>\n",
       "      <td>3509.809076</td>\n",
       "      <td>31.28</td>\n",
       "      <td>210036448</td>\n",
       "      <td>543620741</td>\n",
       "      <td>119540302</td>\n",
       "      <td>22825329</td>\n",
       "      <td>87.30</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>45.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>327</td>\n",
       "      <td>98.2</td>\n",
       "      <td>4118.601264</td>\n",
       "      <td>28.30</td>\n",
       "      <td>303545859</td>\n",
       "      <td>778108502</td>\n",
       "      <td>107048530</td>\n",
       "      <td>23035879</td>\n",
       "      <td>90.26</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>46.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>380</td>\n",
       "      <td>98.5</td>\n",
       "      <td>3423.357824</td>\n",
       "      <td>31.54</td>\n",
       "      <td>295967481</td>\n",
       "      <td>756129104</td>\n",
       "      <td>116249563</td>\n",
       "      <td>33487992</td>\n",
       "      <td>83.89</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>38.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>361</td>\n",
       "      <td>96.3</td>\n",
       "      <td>2476.005983</td>\n",
       "      <td>31.92</td>\n",
       "      <td>262301383</td>\n",
       "      <td>707254342</td>\n",
       "      <td>145440756</td>\n",
       "      <td>29009122</td>\n",
       "      <td>81.32</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "      <td>43.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>398</td>\n",
       "      <td>96.9</td>\n",
       "      <td>4271.639940</td>\n",
       "      <td>31.77</td>\n",
       "      <td>299326071</td>\n",
       "      <td>715544543</td>\n",
       "      <td>183792656</td>\n",
       "      <td>28602201</td>\n",
       "      <td>82.01</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>44.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>330</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3990.900358</td>\n",
       "      <td>31.60</td>\n",
       "      <td>244459157</td>\n",
       "      <td>657576586</td>\n",
       "      <td>180152458</td>\n",
       "      <td>23402892</td>\n",
       "      <td>81.65</td>\n",
       "      <td>85</td>\n",
       "      <td>67</td>\n",
       "      <td>45.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>413</td>\n",
       "      <td>97.1</td>\n",
       "      <td>3702.860263</td>\n",
       "      <td>34.53</td>\n",
       "      <td>314360678</td>\n",
       "      <td>736810175</td>\n",
       "      <td>132609393</td>\n",
       "      <td>54917161</td>\n",
       "      <td>80.50</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>44.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>466</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4073.695183</td>\n",
       "      <td>34.84</td>\n",
       "      <td>310498596</td>\n",
       "      <td>708873675</td>\n",
       "      <td>110620352</td>\n",
       "      <td>24658310</td>\n",
       "      <td>80.73</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>326</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3479.733139</td>\n",
       "      <td>36.61</td>\n",
       "      <td>287447177</td>\n",
       "      <td>879357721</td>\n",
       "      <td>121524280</td>\n",
       "      <td>18060828</td>\n",
       "      <td>80.04</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>52.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>338</td>\n",
       "      <td>96.8</td>\n",
       "      <td>3657.478050</td>\n",
       "      <td>36.84</td>\n",
       "      <td>262935292</td>\n",
       "      <td>586125652</td>\n",
       "      <td>146728325</td>\n",
       "      <td>25861482</td>\n",
       "      <td>76.33</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>53.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>417</td>\n",
       "      <td>95.1</td>\n",
       "      <td>3200.260438</td>\n",
       "      <td>35.36</td>\n",
       "      <td>397939019</td>\n",
       "      <td>952479867</td>\n",
       "      <td>109078772</td>\n",
       "      <td>15622441</td>\n",
       "      <td>81.98</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>50.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>373</td>\n",
       "      <td>100.7</td>\n",
       "      <td>3632.587088</td>\n",
       "      <td>34.64</td>\n",
       "      <td>249119858</td>\n",
       "      <td>778529559</td>\n",
       "      <td>122930471</td>\n",
       "      <td>21265643</td>\n",
       "      <td>83.35</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>49.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>351</td>\n",
       "      <td>98.5</td>\n",
       "      <td>3763.277525</td>\n",
       "      <td>33.93</td>\n",
       "      <td>320716494</td>\n",
       "      <td>856966785</td>\n",
       "      <td>106577192</td>\n",
       "      <td>21085233</td>\n",
       "      <td>83.29</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>48.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>298</td>\n",
       "      <td>95.9</td>\n",
       "      <td>3627.396068</td>\n",
       "      <td>34.93</td>\n",
       "      <td>258917993</td>\n",
       "      <td>842118435</td>\n",
       "      <td>156356878</td>\n",
       "      <td>16043167</td>\n",
       "      <td>83.64</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>45.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>342</td>\n",
       "      <td>95.7</td>\n",
       "      <td>3798.668452</td>\n",
       "      <td>35.98</td>\n",
       "      <td>202440408</td>\n",
       "      <td>691497692</td>\n",
       "      <td>190345295</td>\n",
       "      <td>16288763</td>\n",
       "      <td>87.30</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>49.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>390</td>\n",
       "      <td>99.7</td>\n",
       "      <td>4066.450370</td>\n",
       "      <td>36.54</td>\n",
       "      <td>191774490</td>\n",
       "      <td>752324160</td>\n",
       "      <td>155577968</td>\n",
       "      <td>22319849</td>\n",
       "      <td>75.74</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>49.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>316</td>\n",
       "      <td>101.4</td>\n",
       "      <td>3317.542345</td>\n",
       "      <td>40.38</td>\n",
       "      <td>265249552</td>\n",
       "      <td>675295082</td>\n",
       "      <td>213424960</td>\n",
       "      <td>17534980</td>\n",
       "      <td>74.61</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>55.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>303</td>\n",
       "      <td>98.8</td>\n",
       "      <td>4352.745710</td>\n",
       "      <td>42.98</td>\n",
       "      <td>350954575</td>\n",
       "      <td>856745414</td>\n",
       "      <td>172357228</td>\n",
       "      <td>19907561</td>\n",
       "      <td>77.75</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>58.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>327</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4025.005101</td>\n",
       "      <td>43.09</td>\n",
       "      <td>261251249</td>\n",
       "      <td>686677554</td>\n",
       "      <td>277360157</td>\n",
       "      <td>15498920</td>\n",
       "      <td>81.24</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>61.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>371</td>\n",
       "      <td>98.2</td>\n",
       "      <td>3528.941174</td>\n",
       "      <td>40.99</td>\n",
       "      <td>225927842</td>\n",
       "      <td>583917952</td>\n",
       "      <td>196075479</td>\n",
       "      <td>12171373</td>\n",
       "      <td>82.73</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>64.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>97.9</td>\n",
       "      <td>3486.674137</td>\n",
       "      <td>42.41</td>\n",
       "      <td>265777865</td>\n",
       "      <td>1126712937</td>\n",
       "      <td>286360727</td>\n",
       "      <td>26780133</td>\n",
       "      <td>81.51</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>66.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>248</td>\n",
       "      <td>96.2</td>\n",
       "      <td>3651.540174</td>\n",
       "      <td>39.35</td>\n",
       "      <td>263285557</td>\n",
       "      <td>943633227</td>\n",
       "      <td>133019067</td>\n",
       "      <td>14756425</td>\n",
       "      <td>80.17</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "      <td>63.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>400</td>\n",
       "      <td>100.1</td>\n",
       "      <td>4661.615009</td>\n",
       "      <td>36.34</td>\n",
       "      <td>284538743</td>\n",
       "      <td>983086409</td>\n",
       "      <td>146451183</td>\n",
       "      <td>13136273</td>\n",
       "      <td>85.02</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>98.6</td>\n",
       "      <td>3949.742564</td>\n",
       "      <td>36.74</td>\n",
       "      <td>221982348</td>\n",
       "      <td>882523410</td>\n",
       "      <td>175660650</td>\n",
       "      <td>14438788</td>\n",
       "      <td>79.68</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>71.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>328</td>\n",
       "      <td>97.5</td>\n",
       "      <td>3239.597313</td>\n",
       "      <td>42.70</td>\n",
       "      <td>236116920</td>\n",
       "      <td>701227111</td>\n",
       "      <td>128550254</td>\n",
       "      <td>17615476</td>\n",
       "      <td>79.50</td>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>75.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>311</td>\n",
       "      <td>98.3</td>\n",
       "      <td>3948.559344</td>\n",
       "      <td>39.40</td>\n",
       "      <td>279801349</td>\n",
       "      <td>764216136</td>\n",
       "      <td>213793753</td>\n",
       "      <td>21250415</td>\n",
       "      <td>68.19</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "      <td>75.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>322</td>\n",
       "      <td>91.2</td>\n",
       "      <td>3165.822391</td>\n",
       "      <td>37.91</td>\n",
       "      <td>229710896</td>\n",
       "      <td>851863061</td>\n",
       "      <td>230757873</td>\n",
       "      <td>19511840</td>\n",
       "      <td>73.28</td>\n",
       "      <td>71</td>\n",
       "      <td>84</td>\n",
       "      <td>73.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>350</td>\n",
       "      <td>93.8</td>\n",
       "      <td>3808.477479</td>\n",
       "      <td>36.05</td>\n",
       "      <td>226195368</td>\n",
       "      <td>858464574</td>\n",
       "      <td>282598837</td>\n",
       "      <td>19588774</td>\n",
       "      <td>79.03</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>75.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>304</td>\n",
       "      <td>98.4</td>\n",
       "      <td>3345.931821</td>\n",
       "      <td>33.67</td>\n",
       "      <td>241373894</td>\n",
       "      <td>803726638</td>\n",
       "      <td>214970558</td>\n",
       "      <td>12818304</td>\n",
       "      <td>80.80</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>297</td>\n",
       "      <td>97.2</td>\n",
       "      <td>3594.062462</td>\n",
       "      <td>36.59</td>\n",
       "      <td>389485252</td>\n",
       "      <td>1300409817</td>\n",
       "      <td>199371373</td>\n",
       "      <td>19816125</td>\n",
       "      <td>80.28</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>75.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>323</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3701.793205</td>\n",
       "      <td>37.95</td>\n",
       "      <td>266803639</td>\n",
       "      <td>873823529</td>\n",
       "      <td>134088212</td>\n",
       "      <td>13953344</td>\n",
       "      <td>70.77</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>58.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>332</td>\n",
       "      <td>98.2</td>\n",
       "      <td>3603.267286</td>\n",
       "      <td>33.45</td>\n",
       "      <td>227530304</td>\n",
       "      <td>956236809</td>\n",
       "      <td>136563111</td>\n",
       "      <td>12110446</td>\n",
       "      <td>76.63</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>51.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>299</td>\n",
       "      <td>98.4</td>\n",
       "      <td>3456.261433</td>\n",
       "      <td>39.02</td>\n",
       "      <td>245902532</td>\n",
       "      <td>1004323476</td>\n",
       "      <td>234866048</td>\n",
       "      <td>14146550</td>\n",
       "      <td>74.36</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>61.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>309</td>\n",
       "      <td>89.8</td>\n",
       "      <td>2646.319566</td>\n",
       "      <td>39.48</td>\n",
       "      <td>180097972</td>\n",
       "      <td>730016395</td>\n",
       "      <td>157892383</td>\n",
       "      <td>7662255</td>\n",
       "      <td>68.48</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>65.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>170</td>\n",
       "      <td>93.2</td>\n",
       "      <td>3934.420931</td>\n",
       "      <td>37.10</td>\n",
       "      <td>179460401</td>\n",
       "      <td>944056340</td>\n",
       "      <td>207390450</td>\n",
       "      <td>9721479</td>\n",
       "      <td>70.61</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>67.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>95.5</td>\n",
       "      <td>4929.473764</td>\n",
       "      <td>38.95</td>\n",
       "      <td>159364373</td>\n",
       "      <td>938067587</td>\n",
       "      <td>407621638</td>\n",
       "      <td>13501639</td>\n",
       "      <td>67.57</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>71.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>363</td>\n",
       "      <td>96.8</td>\n",
       "      <td>4363.233925</td>\n",
       "      <td>33.34</td>\n",
       "      <td>219725912</td>\n",
       "      <td>800091488</td>\n",
       "      <td>473506012</td>\n",
       "      <td>17475243</td>\n",
       "      <td>68.13</td>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>64.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>306</td>\n",
       "      <td>99.3</td>\n",
       "      <td>3608.274049</td>\n",
       "      <td>38.53</td>\n",
       "      <td>175431010</td>\n",
       "      <td>627588379</td>\n",
       "      <td>420906139</td>\n",
       "      <td>25791293</td>\n",
       "      <td>69.78</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>65.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>295</td>\n",
       "      <td>99.8</td>\n",
       "      <td>4596.217096</td>\n",
       "      <td>40.34</td>\n",
       "      <td>150790123</td>\n",
       "      <td>891423556</td>\n",
       "      <td>381562411</td>\n",
       "      <td>25453359</td>\n",
       "      <td>62.12</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>65.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>300</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3764.831790</td>\n",
       "      <td>37.09</td>\n",
       "      <td>150639210</td>\n",
       "      <td>754413259</td>\n",
       "      <td>272775593</td>\n",
       "      <td>18203927</td>\n",
       "      <td>51.44</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>60.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>272</td>\n",
       "      <td>89.1</td>\n",
       "      <td>4051.771108</td>\n",
       "      <td>37.48</td>\n",
       "      <td>173228888</td>\n",
       "      <td>663475085</td>\n",
       "      <td>255918459</td>\n",
       "      <td>18332842</td>\n",
       "      <td>37.97</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>61.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>293</td>\n",
       "      <td>71.8</td>\n",
       "      <td>3775.893630</td>\n",
       "      <td>37.16</td>\n",
       "      <td>215817107</td>\n",
       "      <td>895102427</td>\n",
       "      <td>378234408</td>\n",
       "      <td>25142273</td>\n",
       "      <td>46.47</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>60.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>103</td>\n",
       "      <td>72.3</td>\n",
       "      <td>4823.493391</td>\n",
       "      <td>36.00</td>\n",
       "      <td>191370123</td>\n",
       "      <td>669643460</td>\n",
       "      <td>403528354</td>\n",
       "      <td>15199990</td>\n",
       "      <td>45.47</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>63.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month    n  sentiment_lag6  new_units_lag12  GM_lag12  GM_v_lag12  \\\n",
       "0       1  352            93.1      3967.330793     32.62   322791897   \n",
       "1       2  330            91.9      4624.848400     37.31   325763066   \n",
       "2       3  323            87.2      3249.005847     37.50   290497517   \n",
       "3       4  369            90.0      2951.720587     35.06   397017858   \n",
       "4       5  392            91.3      3100.106707     35.97   247974427   \n",
       "5       6  329            92.6      3336.716121     33.33   301968673   \n",
       "6       7  420            92.0      3023.300368     31.51   421897537   \n",
       "7       8  359            91.7      3604.501487     29.44   388156191   \n",
       "8       9  368            91.0      3352.754923     30.02   356102158   \n",
       "9      10  367            89.0      2896.245248     34.91   324318496   \n",
       "10     11  350            94.7      3095.192580     36.20   211953154   \n",
       "11     12  414            93.5      2976.283249     34.01   228926730   \n",
       "12     13  339            90.0      3248.984736     29.64   376807104   \n",
       "13     14  347            89.8      2923.248633     29.44   327501916   \n",
       "14     15  403            91.2      3511.378415     31.43   269313331   \n",
       "15     16  363            87.2      3490.467044     31.80   249296092   \n",
       "16     17  416            93.8      3509.809076     31.28   210036448   \n",
       "17     18  327            98.2      4118.601264     28.30   303545859   \n",
       "18     19  380            98.5      3423.357824     31.54   295967481   \n",
       "19     20  361            96.3      2476.005983     31.92   262301383   \n",
       "20     21  398            96.9      4271.639940     31.77   299326071   \n",
       "21     22  330            97.0      3990.900358     31.60   244459157   \n",
       "22     23  413            97.1      3702.860263     34.53   314360678   \n",
       "23     24  466            95.0      4073.695183     34.84   310498596   \n",
       "24     25  326            93.4      3479.733139     36.61   287447177   \n",
       "25     26  338            96.8      3657.478050     36.84   262935292   \n",
       "26     27  417            95.1      3200.260438     35.36   397939019   \n",
       "27     28  373           100.7      3632.587088     34.64   249119858   \n",
       "28     29  351            98.5      3763.277525     33.93   320716494   \n",
       "29     30  298            95.9      3627.396068     34.93   258917993   \n",
       "30     31  342            95.7      3798.668452     35.98   202440408   \n",
       "31     32  390            99.7      4066.450370     36.54   191774490   \n",
       "32     33  316           101.4      3317.542345     40.38   265249552   \n",
       "33     34  303            98.8      4352.745710     42.98   350954575   \n",
       "34     35  327            98.0      4025.005101     43.09   261251249   \n",
       "35     36  371            98.2      3528.941174     40.99   225927842   \n",
       "36     37  278            97.9      3486.674137     42.41   265777865   \n",
       "37     38  248            96.2      3651.540174     39.35   263285557   \n",
       "38     39  400           100.1      4661.615009     36.34   284538743   \n",
       "39     40  279            98.6      3949.742564     36.74   221982348   \n",
       "40     41  328            97.5      3239.597313     42.70   236116920   \n",
       "41     42  311            98.3      3948.559344     39.40   279801349   \n",
       "42     43  322            91.2      3165.822391     37.91   229710896   \n",
       "43     44  350            93.8      3808.477479     36.05   226195368   \n",
       "44     45  304            98.4      3345.931821     33.67   241373894   \n",
       "45     46  297            97.2      3594.062462     36.59   389485252   \n",
       "46     47  323           100.0      3701.793205     37.95   266803639   \n",
       "47     48  332            98.2      3603.267286     33.45   227530304   \n",
       "48     49  299            98.4      3456.261433     39.02   245902532   \n",
       "49     50  309            89.8      2646.319566     39.48   180097972   \n",
       "50     51  170            93.2      3934.420931     37.10   179460401   \n",
       "51     52    2            95.5      4929.473764     38.95   159364373   \n",
       "52     53  363            96.8      4363.233925     33.34   219725912   \n",
       "53     54  306            99.3      3608.274049     38.53   175431010   \n",
       "54     55  295            99.8      4596.217096     40.34   150790123   \n",
       "55     56  300           101.0      3764.831790     37.09   150639210   \n",
       "56     57  272            89.1      4051.771108     37.48   173228888   \n",
       "57     58  293            71.8      3775.893630     37.16   215817107   \n",
       "58     59  103            72.3      4823.493391     36.00   191370123   \n",
       "\n",
       "     F_v_lag12  TSLA_v_lag3  AN_v_lag3  XOM_lag6  g_best_new_cars_lag3  \\\n",
       "0    596534720    100854710   19192133     79.21                    68   \n",
       "1    524657536     78487987   15208883     75.24                    71   \n",
       "2    609892208     59852189   17266632     74.35                    76   \n",
       "3    539661690     79247152   39619066     82.74                    77   \n",
       "4    428638676    133705697   45371013     81.66                    74   \n",
       "5    577413238    102729544   33490119     77.95                    74   \n",
       "6    672367234    135507264   40381923     77.85                    76   \n",
       "7    596411983    103313344   23858141     80.15                    74   \n",
       "8    743132834    121687759   26540639     83.59                    71   \n",
       "9    669014321     74068654   25137021     88.40                    75   \n",
       "10   443652862     62291339   23977786     89.02                    71   \n",
       "11   587839387     70644512   17778089     93.74                    77   \n",
       "12  1087248662     92133590   18464132     88.95                    67   \n",
       "13   795712499     98886097   23079426     87.14                    73   \n",
       "14   722921118     87993345   18497339     87.28                    78   \n",
       "15   736025667    100683220   18467582     83.32                    75   \n",
       "16   543620741    119540302   22825329     87.30                    76   \n",
       "17   778108502    107048530   23035879     90.26                    76   \n",
       "18   756129104    116249563   33487992     83.89                    75   \n",
       "19   707254342    145440756   29009122     81.32                    81   \n",
       "20   715544543    183792656   28602201     82.01                    81   \n",
       "21   657576586    180152458   23402892     81.65                    85   \n",
       "22   736810175    132609393   54917161     80.50                    85   \n",
       "23   708873675    110620352   24658310     80.73                    84   \n",
       "24   879357721    121524280   18060828     80.04                    80   \n",
       "25   586125652    146728325   25861482     76.33                    78   \n",
       "26   952479867    109078772   15622441     81.98                    75   \n",
       "27   778529559    122930471   21265643     83.35                    75   \n",
       "28   856966785    106577192   21085233     83.29                    84   \n",
       "29   842118435    156356878   16043167     83.64                    76   \n",
       "30   691497692    190345295   16288763     87.30                    75   \n",
       "31   752324160    155577968   22319849     75.74                    78   \n",
       "32   675295082    213424960   17534980     74.61                    80   \n",
       "33   856745414    172357228   19907561     77.75                    84   \n",
       "34   686677554    277360157   15498920     81.24                    81   \n",
       "35   583917952    196075479   12171373     82.73                    81   \n",
       "36  1126712937    286360727   26780133     81.51                    78   \n",
       "37   943633227    133019067   14756425     80.17                    72   \n",
       "38   983086409    146451183   13136273     85.02                    74   \n",
       "39   882523410    175660650   14438788     79.68                    77   \n",
       "40   701227111    128550254   17615476     79.50                    72   \n",
       "41   764216136    213793753   21250415     68.19                    71   \n",
       "42   851863061    230757873   19511840     73.28                    71   \n",
       "43   858464574    282598837   19588774     79.03                    78   \n",
       "44   803726638    214970558   12818304     80.80                    81   \n",
       "45  1300409817    199371373   19816125     80.28                    78   \n",
       "46   873823529    134088212   13953344     70.77                    78   \n",
       "47   956236809    136563111   12110446     76.63                    79   \n",
       "48  1004323476    234866048   14146550     74.36                    65   \n",
       "49   730016395    157892383    7662255     68.48                    65   \n",
       "50   944056340    207390450    9721479     70.61                    68   \n",
       "51   938067587    407621638   13501639     67.57                    76   \n",
       "52   800091488    473506012   17475243     68.13                    72   \n",
       "53   627588379    420906139   25791293     69.78                    62   \n",
       "54   891423556    381562411   25453359     62.12                    65   \n",
       "55   754413259    272775593   18203927     51.44                    76   \n",
       "56   663475085    255918459   18332842     37.97                    76   \n",
       "57   895102427    378234408   25142273     46.47                    84   \n",
       "58   669643460    403528354   15199990     45.47                    74   \n",
       "\n",
       "    g_best_new_cars_lag12  oil_lag12  \n",
       "0                      85      44.83  \n",
       "1                      76      56.83  \n",
       "2                      77      51.06  \n",
       "3                      87      62.21  \n",
       "4                      79      60.47  \n",
       "5                      86      58.79  \n",
       "6                     100      50.51  \n",
       "7                      96      47.01  \n",
       "8                      76      43.58  \n",
       "9                      68      43.66  \n",
       "10                     71      38.93  \n",
       "11                     76      31.27  \n",
       "12                     77      29.11  \n",
       "13                     74      30.13  \n",
       "14                     74      34.33  \n",
       "15                     76      42.70  \n",
       "16                     74      45.15  \n",
       "17                     71      46.27  \n",
       "18                     75      38.97  \n",
       "19                     71      43.91  \n",
       "20                     77      44.63  \n",
       "21                     67      45.83  \n",
       "22                     73      44.80  \n",
       "23                     78      53.30  \n",
       "24                     75      52.19  \n",
       "25                     76      53.40  \n",
       "26                     76      50.43  \n",
       "27                     75      49.33  \n",
       "28                     81      48.69  \n",
       "29                     81      45.63  \n",
       "30                     85      49.97  \n",
       "31                     85      49.36  \n",
       "32                     84      55.20  \n",
       "33                     80      58.53  \n",
       "34                     78      61.06  \n",
       "35                     75      64.47  \n",
       "36                     75      66.28  \n",
       "37                     84      63.97  \n",
       "38                     76      65.87  \n",
       "39                     75      71.02  \n",
       "40                     78      75.18  \n",
       "41                     80      75.68  \n",
       "42                     84      73.62  \n",
       "43                     81      75.74  \n",
       "44                     81      81.48  \n",
       "45                     78      75.24  \n",
       "46                     72      58.33  \n",
       "47                     74      51.55  \n",
       "48                     77      61.19  \n",
       "49                     72      65.28  \n",
       "50                     71      67.23  \n",
       "51                     71      71.91  \n",
       "52                     78      64.15  \n",
       "53                     81      65.60  \n",
       "54                     78      65.53  \n",
       "55                     78      60.11  \n",
       "56                     79      61.09  \n",
       "57                     65      60.52  \n",
       "58                     65      63.83  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
